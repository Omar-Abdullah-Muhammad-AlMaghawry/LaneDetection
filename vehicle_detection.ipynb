{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "import glob\n",
    "import time\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from helpers import convert\n",
    "from scipy.ndimage import label\n",
    "# from featuresourcer import FeatureSourcer\n",
    "\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import functools\n",
    "\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from helpers import convert \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sourcer_params = {\n",
    "  'color_model': 'yuv',                # hls, hsv, yuv, ycrcb\n",
    "  'bounding_box_size': 64,             #\n",
    "  'number_of_orientations': 11,        # 6 - 12\n",
    "  'pixels_per_cell': 16,               # 8, 16\n",
    "  'cells_per_block': 2,                # 1, 2\n",
    "  'do_transform_sqrt': True\n",
    "}\n",
    "\n",
    "start_frame = imread(\"Data/vehicles/KITTI_extracted/5364.png\")\n",
    "\n",
    "ppc_N = sourcer_params['pixels_per_cell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FeatureSourcer:\n",
    "  def __init__(self, p, start_frame):\n",
    "    \n",
    "    self.color_model = p['color_model']\n",
    "    self.s = p['bounding_box_size']\n",
    "    \n",
    "    self.ori = p['number_of_orientations']\n",
    "    self.ppc = (p['pixels_per_cell'], p['pixels_per_cell'])\n",
    "    self.cpb = (p['cells_per_block'], p['cells_per_block']) \n",
    "    self.do_sqrt = p['do_transform_sqrt']\n",
    "\n",
    "    self.ABC_img = None\n",
    "    self.dims = (None, None, None)\n",
    "    self.hogA, self.hogB, self.HogC = None, None, None\n",
    "    self.hogA_img, self.hogB_img, self.hogC = None, None, None\n",
    "    \n",
    "    self.RGB_img = start_frame\n",
    "    self.new_frame(self.RGB_img)\n",
    "\n",
    "  def hogFn(self, channel):\n",
    "    features, hog_img = hog(channel, \n",
    "                            orientations = self.ori, \n",
    "                            pixels_per_cell = self.ppc,\n",
    "                            cells_per_block = self.cpb, \n",
    "                            transform_sqrt = self.do_sqrt,\n",
    "                            visualize = True, \n",
    "                            feature_vector = False)\n",
    "    return features, hog_img\n",
    "\n",
    "  def new_frame(self, frame):\n",
    "    \n",
    "    self.RGB_img = frame \n",
    "    self.ABC_img = convert(frame, src_model= 'rgb', dest_model = self.color_model)\n",
    "    self.dims = self.RGB_img.shape\n",
    "    \n",
    "    self.hogA, self.hogA_img = self.hogFn(self.ABC_img[:, :, 0])\n",
    "    self.hogB, self.hogB_img = self.hogFn(self.ABC_img[:, :, 1])\n",
    "    self.hogC, self.hogC_img = self.hogFn(self.ABC_img[:, :, 2])\n",
    "    \n",
    "  def slice(self, x_pix, y_pix, w_pix = None, h_pix = None):\n",
    "        \n",
    "    x_start, x_end, y_start, y_end = self.pix_to_hog(x_pix, y_pix, h_pix, w_pix)\n",
    "    \n",
    "    hogA = self.hogA[y_start: y_end, x_start: x_end].ravel()\n",
    "    hogB = self.hogB[y_start: y_end, x_start: x_end].ravel()\n",
    "    hogC = self.hogC[y_start: y_end, x_start: x_end].ravel()\n",
    "    hog = np.hstack((hogA, hogB, hogC))\n",
    "\n",
    "    return hog \n",
    "\n",
    "  def features(self, frame):\n",
    "    self.new_frame(frame)\n",
    "    return self.slice(0, 0, frame.shape[1] , frame.shape[0])######################added *ppc_N\n",
    "\n",
    "  def visualize(self):\n",
    "    return self.RGB_img, self.hogA_img, self.hogB_img, self.hogC_img\n",
    "\n",
    "  def pix_to_hog(self, x_pix, y_pix, h_pix, w_pix):\n",
    "\n",
    "    if h_pix is None and w_pix is None: \n",
    "      h_pix, w_pix = self.s, self.s\n",
    "    \n",
    "    h = h_pix // self.ppc[0]\n",
    "    w = w_pix // self.ppc[0]\n",
    "    y_start = y_pix // self.ppc[0]\n",
    "    x_start = x_pix // self.ppc[0]\n",
    "    y_end = y_start + h - 1\n",
    "    x_end = x_start + w - 1\n",
    "    \n",
    "    return x_start, x_end, y_start, y_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sourcer_params = {\n",
    "  'color_model': 'yuv',                # hls, hsv, yuv, ycrcb\n",
    "  'bounding_box_size': 64,             #\n",
    "  'number_of_orientations': 11,        # 6 - 12\n",
    "  'pixels_per_cell': 16,               # 8, 16\n",
    "  'cells_per_block': 2,                # 1, 2\n",
    "  'do_transform_sqrt': True\n",
    "}\n",
    "\n",
    "start_frame = imread(\"Data/vehicles/KITTI_extracted/5364.png\")\n",
    "\n",
    "ppc_N = sourcer_params['pixels_per_cell']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcer = FeatureSourcer(sourcer_params, start_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading images to memory...\")\n",
    "t_start = time.time()\n",
    "\n",
    "vehicle_imgs, nonvehicle_imgs = [], []\n",
    "vehicle_paths = glob.glob('Data/vehicles/*/*.png')\n",
    "nonvehicle_paths = glob.glob('Data/non-vehicles/*/*.png')\n",
    "\n",
    "for path in vehicle_paths: vehicle_imgs.append(imread(path))\n",
    "for path in nonvehicle_paths: nonvehicle_imgs.append(imread(path))\n",
    "\n",
    "vehicle_imgs, nonvehicle_imgs = np.asarray(vehicle_imgs), np.asarray(nonvehicle_imgs)\n",
    "total_vehicles, total_nonvehicles = vehicle_imgs.shape[0], nonvehicle_imgs.shape[0]\n",
    "\n",
    "print(\"... Done\")\n",
    "print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
    "print(\"Vehicle images shape: \", vehicle_imgs.shape)\n",
    "print(\"Non-vehicle images shape: \", nonvehicle_imgs.shape)\n",
    "\n",
    "print(\"Extracting features... This might take a while...\")\n",
    "t_start = time.time()\n",
    "\n",
    "vehicles_features, nonvehicles_features = [], []\n",
    "\n",
    "print(\"Vehicles...\")\n",
    "for img in vehicle_imgs:\n",
    "  vehicles_features.append(sourcer.features(img))\n",
    "  print('█', end = '')\n",
    "\n",
    "print()\n",
    "print(\"Non-Vehicles...\")\n",
    "for img in nonvehicle_imgs:\n",
    "  nonvehicles_features.append(sourcer.features(img))\n",
    "  print('█', end = '')\n",
    "                         \n",
    "vehicles_features = np.asarray(vehicles_features)\n",
    "nonvehicles_features = np.asarray(nonvehicles_features)\n",
    "\n",
    "print()\n",
    "print(\"...Done\")\n",
    "print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
    "print(\"Vehicles features shape: \", vehicles_features.shape)\n",
    "print(\"Non-vehicles features shape: \", nonvehicles_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameters\n",
    "\n",
    "vehiclesFeatures = vehicles_features \n",
    "nonVehiclesFeatures = nonvehicles_features\n",
    "\n",
    "totalVehicles,totalNonVehicles = total_vehicles,total_nonvehicles\n",
    "\n",
    "\n",
    "\n",
    "def    newFrame(strip):\n",
    "    sourcer.new_frame(strip)\n",
    "    return 0\n",
    "\n",
    "##this function have to return hog features\n",
    "def hogSliceFn(strip, resizedX , y, boundingBoxSizeX, boundingBoxSizeY):\n",
    "\n",
    "    # sourcer.features(strip)\n",
    "    return sourcer.slice( resizedX, y, w_pix = boundingBoxSizeX, h_pix = boundingBoxSizeY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##scaling features for training \n",
    "def scalingFn(vehiclesFeatures, nonVehiclesFeatures,totalVehicles,totalNonVehicles, pathSaveModel = 'scaler.pkl'):\n",
    "    ##put all features vectors beside eachothers\n",
    "    unscaledX = np.vstack((vehiclesFeatures, nonVehiclesFeatures)).astype(np.float64)\n",
    "    \n",
    "    #In SVM, data normalization is required to use all kernels related to distance calculation.\n",
    "    ##standardizion (mean = 0, std = 1) the data which by centerized it and divide by standaard division. betwise the normalize it (the data range bet 0 to 1)\n",
    "    scalerM = StandardScaler() #creating the module for the standardization\n",
    "    scaler = scalerM.fit(unscaledX) #Compute the mean and standard devision to be used for later scaling.\n",
    "    x = scaler.transform(unscaledX) #Perform standardization by centering and scaling.\n",
    "    y= np.hstack((np.ones(totalVehicles),np.zeros(totalNonVehicles)))\n",
    "\n",
    "\n",
    "    print (\"Saving models...\")\n",
    "    #save the scaler model\n",
    "    joblib.dump(scaler,pathSaveModel )\n",
    "    print (\"Saving models...\")\n",
    "\n",
    "    return x, y, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scaling features...\")\n",
    "t_start = time.time()\n",
    "\n",
    "xScaledFeatured,yScaledFeatured,scaler = scalingFn(vehiclesFeatures, nonVehiclesFeatures,totalVehicles,totalNonVehicles, pathSaveModel = 'scaler.pkl')\n",
    "\n",
    "print(\"...Done\")\n",
    "print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
    "print(\" x shape: \", xScaledFeatured.shape, \" y shape: \", yScaledFeatured.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##training the data \n",
    "\n",
    "def trainFn(xScaledFeatured,yScaledFeatured, pathSaveModel = 'svc.pkl'):\n",
    "\n",
    "    #split the data bet the training which 70% vs the test wich is 30%, also the chosen data are randomly by precent (rand_state)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xScaledFeatured,yScaledFeatured, test_size = 0.3,  random_state =rand.randint(1,100))\n",
    "    \n",
    "    # SVM is used for both classification and regression problems.\n",
    "    # Scikit-learn's method of Support Vector Classification (SVC) can be extended to solve regression problems as well. \n",
    "    # That extended method is called Support Vector Regression (SVR).\n",
    "    \n",
    "    #creating the model\n",
    "    #svm with linear (also line spearate between the samples ) kernal not segmoid or tanh or relu, between the bars of neural nodes\n",
    "    svc = LinearSVC() \n",
    "\n",
    "    #traning the model with the traintng data data\n",
    "    svc.fit(xTrain,yTrain)\n",
    "\n",
    "    #check the accuracy of the model by the testing data\n",
    "    accuracy = svc.score(xTest,yTest)\n",
    "    \n",
    "    print (\"Saving models...\")\n",
    "    joblib.dump(svc, pathSaveModel)\n",
    "    print(\"...Done\")\n",
    "  \n",
    "    return svc , accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training classifier...\")\n",
    "t_start = time.time()\n",
    "\n",
    "svc , accuracy = trainFn(xScaledFeatured,yScaledFeatured, pathSaveModel = 'svc.pkl')\n",
    "\n",
    "\n",
    "\n",
    "print(\"...Done\")\n",
    "print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
    "print(\"Accuracy: \", np.round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predict func \n",
    "\n",
    "def predictFn(frameFeature, svc, ScalerModel):\n",
    "    \n",
    "    #scale (standrize) the feature, which i use to predict, \n",
    "    frameScaled = ScalerModel.transform([frameFeature])\n",
    "\n",
    "    #make the prediction\n",
    "    frameClass = svc.predict(frameScaled)\n",
    "\n",
    "    #return the frame class as int\n",
    "    return np.int(frameClass[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the models\n",
    "print (\"Loading models...\")\n",
    "\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "svc = joblib.load(\"svc.pkl\")\n",
    "\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcer = FeatureSourcer(sourcer_params, start_frame)\n",
    "\n",
    "f1 = sourcer.features(nonvehicle_imgs[rand.randint(0, totalNonVehicles)])\n",
    "f2 = sourcer.features(vehicle_imgs[rand.randint(0, totalVehicles)])\n",
    "f3 = sourcer.features(vehicle_imgs[rand.randint(0, totalVehicles)])\n",
    "f4 = sourcer.features(nonvehicle_imgs[rand.randint(0, totalNonVehicles)])\n",
    "\n",
    "\n",
    "print(predictFn(f4, svc, scaler))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Helper functions####\n",
    "\n",
    "#get the start and the size of each box, and get the end postion for it\n",
    "def boxBoundaries(box):\n",
    "    xStart = box[0]\n",
    "    yStart = box[1]\n",
    "    xEnd = box[0] + box[2]\n",
    "    yEnd = box[1] + box[2]\n",
    "    return xStart , yStart, xEnd, yEnd \n",
    "\n",
    "def drawBoxes(frame, boxes, color = (255,0,0),thick= 10):\n",
    "\n",
    "    #take a copy from the original image to draw on it all the boxes we want to draw\n",
    "    outImage = frame.copy()\n",
    "\n",
    "    #take every box we want to draw on the image,\n",
    "    #and draw each one of them indvadully\n",
    "    for box in boxes:\n",
    "\n",
    "        #get the start position, and the end postion for each traingle\n",
    "        xStart , yStart, xEnd, yEnd = boxBoundaries(box)\n",
    "\n",
    "        #draw the rectangle on the image\n",
    "        cv2.rectangle(outImage, (xStart , yStart),(xEnd, yEnd), color, thick)\n",
    "\n",
    "    return outImage\n",
    "\n",
    "#show images function\n",
    "def showImages(images,nrows,ncols, width, height, depth = 80):\n",
    "    fig, ax = plt.subplots(nrows= nrows, ncols=ncols, figsize= (width,height),dpi = depth)\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        img= images[i]\n",
    "        ax[i].imshow(img)\n",
    "\n",
    "    for i in range(nrows*ncols):\n",
    "        ax[i].axis('off')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##slider : we choose only part of the frame which we call strip to extract the hog feature from it,\n",
    "#   then predic it every slice on it\n",
    "\n",
    "#prepare the part we work on to extract the feature, and classify each half cel on it\n",
    "def prepareSlider(frame , yStart,windowSize,boundingBoxSize):\n",
    "    \n",
    "    scaler = windowSize / boundingBoxSize ##for ex 80 /64\n",
    "    \n",
    "    #for the strip we get the end\n",
    "    yEnd = yStart + windowSize\n",
    "\n",
    "    #the width of the strip which we use it to resize the the stip\n",
    "    #which will be smaller than the fram width frame by (boundaryBox(64) / windowSize(80) ) \n",
    "    #and equal to mulible of boundary boxes by (widthFrame(1024) / windowSize(80)) ~ 12.55\n",
    "    newWidth = np.int(frame.shape[1] / scaler) # width = boundaryBox(64) * (widthFrame / windowSize(80))\n",
    "\n",
    "    #take the required strip from the frame\n",
    "    strip = frame[yStart : yEnd, :]\n",
    "\n",
    "    #resize this strip\n",
    "    strip = cv2.resize(strip,(newWidth,boundingBoxSize ))\n",
    "\n",
    "    return strip, scaler\n",
    "\n",
    "\n",
    "#to locate the vehicles from the frame\n",
    "def locateVehicle(frame, yWindowPosition, windowSize, boundingBoxSize, inc, svcModelPath = 'svc.pkl',ScalarModelPath = 'scaler.pkl') :\n",
    "    \n",
    "    #load the classifier model\n",
    "    svc =  joblib.load(svcModelPath)\n",
    "    ScalarModel = joblib.load(ScalarModelPath)\n",
    "\n",
    "    #prepare the part we work on to extract the feature, and classify each half cel on it\n",
    "    strip , scaler = prepareSlider(frame , yWindowPosition,windowSize,boundingBoxSize)\n",
    "\n",
    "    #boxes which we found the car on it, and want to draw pox on it\n",
    "    boxes = []\n",
    "\n",
    "    #make hog to every channel of the strip , in the new frame\n",
    "    newFrame(strip)\n",
    "\n",
    "    #just count number of the boxes (blocks) in the width of the strip and substract one from it\n",
    "    #by taking the floor (stripWidth / boundingBoxSize) => 12 to there no be fractions, then multyply it on  boundingBoxSize => 12 * 64\n",
    "    # the substract one boundingBoxSize from it => 11 * 64\n",
    "    #which will be the last x we extract the hog and classfy it \n",
    "    xEnd = (strip.shape[1] // boundingBoxSize - 1) * boundingBoxSize\n",
    "\n",
    "    for resizedX in range(0, xEnd, inc): #if inc = 8 #0,8,16,24, 32, 40, 56, 64, 72, ......\n",
    "\n",
    "        #extract the features from one slice from the the strip\n",
    "        # if resizedX = 16 , then iside xStart = floor( 16/pixelpercell) = 1 , width = floor(boundingBoxSize / pexelPerCell) =64/16 = 4, xend = 1 + 4 -1  = 4\n",
    "        #yStart = 0 / pixelPerCell = 0, height =boundingBoxSize / pexelPerCell  = 4 , yend = 0 + 4 \n",
    "        #get the feature vector which compines from the 3 channels put besides each other\n",
    "            #yStartof the real frame  which is the same of the y of window box(yWindowPosition) \n",
    "            #because we don't move from the start of the strip = 0 which is represent the yWindowPosition #so the inY here is  = 0\n",
    "            ### we go through only the top of the strip because if that slice is a part of vehicle, so the whole window is a vehicle \n",
    "            #####also maybe if we get part of the car, it will be a car for all the window postion\n",
    "        features = hogSliceFn(strip, resizedX , 0, boundingBoxSize  , boundingBoxSize)\n",
    "\n",
    "\n",
    "        #after extraction \n",
    "        #we classify (predict)\n",
    "        #if it's a car we get the xStart position of it in the real fram image not the strip\n",
    "        if predictFn(features, svc, ScalarModel):\n",
    "\n",
    "            #xStart = resizedX of the strip* (windowSize / boundingBoxSize) ##for ex 16 *( 80 /64)\n",
    "            #because we divide the width of the frame by the scaler, so we multyply it again\n",
    "            xStartV = np.int(scaler * resizedX) \n",
    "\n",
    "            #we append every thing about that car, like xStart, yStart which is the same of the y of window box \n",
    "            #because we don't move from the start of the strip = 0 which is represent the yWindowPosition\n",
    "            #also maybe if we get part of the car, it will be a car for all the window postion\n",
    "            boxes.append((xStartV, yWindowPosition, windowSize))\n",
    "\n",
    "\n",
    "    return boxes, strip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get all copies of the images \n",
    "def slider(frame,  windowSizes, stripPostions , boundingBoxSize, inc, svcModelPath = 'svc.pkl' , ScalarModelPath = 'scaler.pkl'):\n",
    "\n",
    "    boxedImages = []\n",
    "    strips = []\n",
    "    boungingBoxesTotal = [] \n",
    "    ##we go through differnt strip postions on the original frame 410, 390, 380, 380\n",
    "    # to see if there is a vehicles close to the my car or far away\n",
    "    #also we got through differen windows because\n",
    "    #maybe there different size of the vichels \n",
    "\n",
    "    ######## the main reason ###################\n",
    "    # because we classify only the top of the stip \n",
    "    # so we can deal if it's a shadow (false positive) or a car (true positive) so we classify the same vehicle from diffiernt postion\n",
    "    for yWindowPosition, windowSize in zip(stripPostions, windowSizes):\n",
    "\n",
    "        # Get the vehicles boxes (xStart, yStart, windowsSize) of the original frame from the first strip , second, third, and forth\n",
    "        boundingBoxes, strip = locateVehicle(frame, yWindowPosition, windowSize, boundingBoxSize, inc, svcModelPath,ScalarModelPath)\n",
    "\n",
    "        for boundingBox in boundingBoxes:#################################added#########################\n",
    "            boungingBoxesTotal.append(boundingBox)\n",
    "\n",
    "        #draw rectangles on each vehicle (of that strip), on a copy from the same original frame, no change for the frame\n",
    "        boxedImage = drawBoxes(frame, boundingBoxes)\n",
    "\n",
    "        #collect these copies of the images for the same original frame\n",
    "        boxedImages.append(boxedImage)\n",
    "\n",
    "        #collect the strips we work on together\n",
    "        strips.append(strip)\n",
    "\n",
    "\n",
    "    return boungingBoxesTotal, boxedImages, strips\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = imread(\"Project_data/test_images/test1.jpg\")\n",
    "frame2 = imread(\"Project_data/test_images/test2.jpg\")\n",
    "frame3 = imread(\"Project_data/test_images/test3.jpg\")\n",
    "frame4 = imread(\"Project_data/test_images/test4.jpg\")\n",
    "frame5 = imread(\"Project_data/test_images/test5.jpg\")\n",
    "frame6 = imread(\"Project_data/test_images/test6.jpg\")\n",
    "windowSizes = 80, 120, 150, 180\n",
    "stripPostions = 410, 390,  380, 380\n",
    "\n",
    "boundingBoxSize = sourcer_params['bounding_box_size']\n",
    "# slider1 = Slider(sourcer = sourcer, ScalerModelPath=\"scaler.pkl\", svcModelPath=\"svc.pkl\", increment = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test the sliding windows\n",
    "boungingBoxesTotal, boxedImages, strips = slider(frame5 , windowSizes, stripPostions , boundingBoxSize, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImages(strips, ncols=  len(strips), nrows=  1, width=  15, height=  3)\n",
    "showImages(boxedImages, ncols = len(boxedImages), nrows = 1, width = 15, height = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeatmapThresh(heatmap, threshold=1):\n",
    "    res = np.zeros(heatmap.shape)\n",
    "    res[heatmap > threshold] = 1\n",
    "    return res\n",
    "\n",
    "def HeatmapDraw(thresh_map, frame, color=(0,255,0), thickness=10):\n",
    "    labeled, num_labels = label(thresh_map)\n",
    "    for i in range(1, num_labels + 1):\n",
    "        xs, ys = (labeled == i).nonzero()\n",
    "        p1 = (np.min(ys), np.min(xs))\n",
    "        p2 = (np.max(ys), np.max(xs))\n",
    "        cv2.rectangle(frame, p1, p2, color, thickness)\n",
    "    return frame\n",
    "\n",
    "def HeatmapCord_Draw( frame, thresh_map,color=(0,255,0), thickness=10):\n",
    "    labeled, num_labels = label(thresh_map)\n",
    "    p = []\n",
    "    for i in range(1, num_labels + 1):\n",
    "        xs, ys = (labeled == i).nonzero()\n",
    "        p1 = (np.min(ys), np.min(xs))\n",
    "        p2 = (np.max(ys), np.max(xs))\n",
    "        p.append(( p1 , p2 ))\n",
    "        cv2.rectangle(frame, p1, p2, color, thickness)\n",
    "\n",
    "    return frame, p, labeled\n",
    "\n",
    "def HeatmapAdd(heatmap, pos_x, pos_y, win_size):\n",
    "        heatmap[pos_y : (pos_y + win_size), pos_x : (pos_x + win_size)] += 1\n",
    "        return heatmap\n",
    "\n",
    "def HeatmapUpdate(heatmap, boxes):\n",
    "    for b in boxes:\n",
    "        x, y, size = b\n",
    "        HeatmapAdd(heatmap, x, y, size)\n",
    "    return heatmap\n",
    "\n",
    "# heat = np.zeros((720, 1280))\n",
    "# thresh_map = np.zeros(heat.shape)\n",
    "\n",
    "# heat = HeatmapUpdate(heat, boxes)\n",
    "\n",
    "# thresh_map = HeatmapThresh(heat)\n",
    "\n",
    "# test_frame = HeatmapDraw(thresh_map, test_frame)\n",
    "# plt.imshow(test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verBoseFn(frame,  windowSizes, stripPostions , boundingBoxSize, inc, threshold, svcModelPath = 'svc.pkl' , ScalarModelPath = 'scaler.pkl'):\n",
    "\n",
    "    boxedImages = []\n",
    "    strips = []\n",
    "    boungingBoxesTotal = [] \n",
    "    heat = np.zeros(frame.shape[0:2])\n",
    "    thresh_map = np.zeros(heat.shape)\n",
    "    ##we go through differnt strip postions on the original frame 410, 390, 380, 380\n",
    "    # to see if there is a vehicles close to the my car or far away\n",
    "    #also we got through differen windows because\n",
    "    #maybe there different size of the vichels \n",
    "\n",
    "    ######## the main reason ###################\n",
    "    # because we classify only the top of the stip \n",
    "    # so we can deal if it's a shadow (false positive) or a car (true positive) so we classify the same vehicle from diffiernt postion\n",
    "    for yWindowPosition, windowSize in zip(stripPostions, windowSizes):\n",
    "\n",
    "        # Get the vehicles boxes (xStart, yStart, windowsSize) of the original frame from the first strip , second, third, and forth\n",
    "        boundingBoxes, strip = locateVehicle(frame, yWindowPosition, windowSize, boundingBoxSize, inc, svcModelPath,ScalarModelPath)\n",
    "\n",
    "        heat = HeatmapUpdate(heat, boundingBoxes)\n",
    "    \n",
    "\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.imshow(heat, cmap='hot')\n",
    "\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.imshow(hm.thresh_map,  cmap='gray')\n",
    "\n",
    "    # test_frame = np.zeros((720, 1280, 3))\n",
    "    thresh_map = HeatmapThresh(heat, threshold=threshold)\n",
    "    frameOut = HeatmapDraw(thresh_map, frame)\n",
    "    # plt.imshow(frameOut)\n",
    "\n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameOut = verBoseFn(frame5 , windowSizes, stripPostions , boundingBoxSize, 8, 1)\n",
    "\n",
    "plt.imshow(frameOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verBoseEdited (frame):\n",
    "    # windowSizes = 180, 100, 120, 140, 180, 210\n",
    "    # stripPostions = 360, 390, 390, 390, 390, 390\n",
    "    windowSizes = 180, 100, 120, 140 #80,96,160,192\n",
    "    stripPostions = 360, 390, 390, 390 #\n",
    "    inc = 8\n",
    "    threshold = 1\n",
    "\n",
    "    frameOut =verBoseFn(frame,  windowSizes, stripPostions , boundingBoxSize, inc, threshold, svcModelPath = 'svc.pkl' , ScalarModelPath = 'scaler.pkl')\n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_debug_board(img0, bboxes, hot_windows, heatmap, labels):\n",
    "\n",
    "def draw_debug_board(img0, hot_windows, heatmap, threshold):\n",
    "    \n",
    "    img1 = np.copy(img0)\n",
    "\n",
    "    img = np.copy(img0)\n",
    "\n",
    "    thresh_map = HeatmapThresh(heatmap, threshold=threshold)\n",
    "    img ,posMinMax , labels =HeatmapCord_Draw(img1,thresh_map)\n",
    "    # plt.imshow(frameOut)\n",
    "    bboxes = posMinMax\n",
    "    # hot_windows = boungingBoxesTotal\n",
    "    \n",
    "    \n",
    "    # prepare RGB heatmap image from float32 heatmap channel\n",
    "    img_heatmap = (np.copy(heatmap) / np.max(heatmap) * 255.).astype(np.uint8);\n",
    "    img_heatmap = cv2.applyColorMap(img_heatmap, colormap=cv2.COLORMAP_HOT)\n",
    "    img_heatmap = cv2.cvtColor(img_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # prepare RGB labels image from float32 labels channel\n",
    "    img_labels = (np.copy(labels) / np.max(labels) * 255.).astype(np.uint8);\n",
    "    img_labels = cv2.applyColorMap(img_labels, colormap=cv2.COLORMAP_HOT)\n",
    "    img_labels = cv2.cvtColor(img_labels, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # draw hot_windows in the frame\n",
    "    img_hot_windows = np.copy(img)\n",
    "    img_hot_windows = drawBoxes(img_hot_windows, hot_windows, thick=2)\n",
    "    \n",
    "    ymax = 0\n",
    "    \n",
    "    board_x = 5\n",
    "    board_y = 5\n",
    "    board_ratio = (img.shape[0] - 3*board_x)//3 / img.shape[0] #0.25\n",
    "    board_h = int(img.shape[0] * board_ratio)\n",
    "    board_w = int(img.shape[1] * board_ratio)\n",
    "        \n",
    "    ymin = board_y\n",
    "    ymax = board_h + board_y\n",
    "    xmin = board_x\n",
    "    xmax = board_x + board_w\n",
    "\n",
    "    offset_x = board_x + board_w\n",
    "\n",
    "    # draw hot_windows in the frame\n",
    "    img_hot_windows = cv2.resize(img_hot_windows, dsize=(board_w, board_h), interpolation=cv2.INTER_LINEAR)\n",
    "    img[ymin:ymax, xmin:xmax, :] = img_hot_windows\n",
    "    \n",
    "    # draw heatmap in the frame\n",
    "    xmin += offset_x\n",
    "    xmax += offset_x\n",
    "    img_heatmap = cv2.resize(img_heatmap, dsize=(board_w, board_h), interpolation=cv2.INTER_LINEAR)\n",
    "    img[ymin:ymax, xmin:xmax, :] = img_heatmap\n",
    "    \n",
    "    # draw heatmap in the frame\n",
    "    xmin += offset_x\n",
    "    xmax += offset_x\n",
    "    img_labels = cv2.resize(img_labels, dsize=(board_w, board_h), interpolation=cv2.INTER_LINEAR)\n",
    "    img[ymin:ymax, xmin:xmax, :] = img_labels\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verBoseFnDebug(frame,  windowSizes, stripPostions , boundingBoxSize, inc, threshold, svcModelPath = 'svc.pkl' , ScalarModelPath = 'scaler.pkl'):\n",
    "\n",
    "    boxedImages = []\n",
    "    strips = []\n",
    "    boungingBoxesTotal = [] \n",
    "    heat = np.zeros(frame.shape[0:2])\n",
    "    thresh_map = np.zeros(heat.shape)\n",
    "    ##we go through differnt strip postions on the original frame 410, 390, 380, 380\n",
    "    # to see if there is a vehicles close to the my car or far away\n",
    "    #also we got through differen windows because\n",
    "    #maybe there different size of the vichels \n",
    "\n",
    "    ######## the main reason ###################\n",
    "    # because we classify only the top of the stip \n",
    "    # so we can deal if it's a shadow (false positive) or a car (true positive) so we classify the same vehicle from diffiernt postion\n",
    "    for yWindowPosition, windowSize in zip(stripPostions, windowSizes):\n",
    "\n",
    "        # Get the vehicles boxes (xStart, yStart, windowsSize) of the original frame from the first strip , second, third, and forth\n",
    "        boundingBoxes, strip = locateVehicle(frame, yWindowPosition, windowSize, boundingBoxSize, inc, svcModelPath,ScalarModelPath)\n",
    "        \n",
    "        for  boundingBox in boundingBoxes:\n",
    "            boungingBoxesTotal.append(boundingBox)    \n",
    "        # boungingBoxesTotal.append(boundingBox for boundingBox in boundingBoxes)\n",
    "\n",
    "        heat = HeatmapUpdate(heat, boundingBoxes)\n",
    "    \n",
    "\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.imshow(heat, cmap='hot')\n",
    "\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.imshow(hm.thresh_map,  cmap='gray')\n",
    "\n",
    "    # test_frame = np.zeros((720, 1280, 3))\n",
    "    # thresh_map = HeatmapThresh(heat, threshold=threshold)\n",
    "    # posMinMax , labeled =HeatmapCord(thresh_map)\n",
    "    # # plt.imshow(frameOut)\n",
    "    # bboxes = posMinMax\n",
    "    hot_windows = boungingBoxesTotal\n",
    "    \n",
    "    # hot_windows = [((boundingBox[0]+boundingBox[2]),(boundingBox[1]+boundingBox[2])) for boundingBox in boungingBoxesTotal] \n",
    "\n",
    "    frameOut = draw_debug_board(frame, hot_windows, heat, threshold)\n",
    "\n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameOut = verBoseFnDebug(frame1 , windowSizes, stripPostions , boundingBoxSize, 8, 1)\n",
    "\n",
    "plt.imshow(frameOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verBoseEditedDebug (frame):\n",
    "    # windowSizes = 180, 100, 120, 140, 180, 210\n",
    "    # stripPostions = 360, 390, 390, 390, 390, 390\n",
    "    windowSizes = 180, 100, 120, 140 #80,96,160,192\n",
    "    # windowSizes = 80,96,160,192\n",
    "\n",
    "    stripPostions = 360, 390, 390, 390\n",
    "    inc = 8\n",
    "    threshold = 1\n",
    "\n",
    "    frameOut =verBoseFnDebug(frame,  windowSizes, stripPostions , boundingBoxSize, inc, threshold, svcModelPath = 'svc.pkl' , ScalarModelPath = 'scaler.pkl')\n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################with debug mode################\n",
    "\n",
    "# heatmap = HeatMap( thresh_val=  1)\n",
    "\n",
    "deubug = 1\n",
    "inputVideoPath ='Project_data/project_video.mp4'\n",
    "# inputVideoPath ='Project_Data/challenge_video.mp4'\n",
    "# inputVideoPath = 'Project_Data/harder_challenge_video.mp4'\n",
    "\n",
    "projectOutput = 'project_output.mp4'\n",
    "\n",
    "\n",
    "clip1 = VideoFileClip(inputVideoPath)\n",
    "# clip1 = VideoFileClip('Project_Data/challenge_video.mp4')\n",
    "# clip1 = VideoFileClip('Project_Data/harder_challenge_video.mp4')\n",
    "\n",
    "\n",
    "# verBosePartial = functools.partial(verBose,windowSizes = windowSizes, stripPostions =stripPostions , boundingBoxSize = boundingBoxSize, inc = 8 )\n",
    "# whiteClip = clip1.fl_image(verBosePartial)\n",
    "\n",
    "\n",
    "if deubug != 1:\n",
    "        whiteClip = clip1.fl_image(verBoseEdited)\n",
    "else :\n",
    "        whiteClip = clip1.fl_image(verBoseEditedDebug)\n",
    "\n",
    "\n",
    "whiteClip.write_videofile(projectOutput,audio= False)\n",
    "        # threads=5, \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(projectOutput))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
